#PBS -P CBBI0825 
#PBS -M matthys.potgieter@gmail.com 
#PBS -l select=10:ncpus=24:nodetype=haswell_reg
#PBS -l walltime=48:00:00
#PBS -N MyJob
#PBS -q normal
#PBS -m be

# Parameters
output_folder='/mnt/lustre/users/mpotgieter1/andrew_stool_out/andrew_PAM30_Universal'
bp_input_fasta='/mnt/lustre/users/mpotgieter1/andrew_stool_out/combined_sequences.fasta'
bp_query_max_len=50      # maximum peptide length
bp_query_min_len=7       # minimum peptide length
bp_python_chunknumber=240 # chunknumber = cores available, set threads to 1

bp_blast_evalue=200000
bp_blast_matrix='PAM30'
bp_blast_gap_open=9
bp_blast_gap_extend=1
bp_blast_word_size=4
bp_blast_num_threads=1
bp_blast_outfmt=5
bp_blast_max_target_seqs=2
bp_blast_max_hsps=1
bp_blast_BLASTDB_DIR='/mnt/lustre/users/mpotgieter1/uniprot/uniprot_current'
bp_blast_BLASTDB='UniProtCurrent'

bp_sum_aln_cutoff=2
bp_sum_pept2lca=1

bp_gnu_parallel_j=24
headnode_user_ip=mpotgieter1@lengau.chpc.ac.za  #headnode user account - NB for derivative qsub jobs
unipept_q='serial'
unipept_l='select=1:ncpus=24:mpiprocs=24'
unipept_P='CBBI0825'
############
# Pipeline #
############

set -e
cd ${PBS_O_WORKDIR}
module add chpc/gnu/parallel-20160422


# Create output folder if needed
if [ ! -d $output_folder ] ; then
    mkdir $output_folder
fi

# Check that config does not exist or is unchanged
if [ ! -f $output_folder/pipeline.pbs ] ; then
    cp "$(readlink -f $0)" $output_folder/pipeline.pbs
else
    cmp --silent "$(readlink -f $0)" $output_folder/pipeline.pbs && echo "'$(readlink -f $0)' unchanged."|| { echo "'$(readlink -f $0)' has changed, please delete '$output_folder' or replace '$(readlink -f $0)' with the contents of pipeline.sh in "${output_folder}; exit 1; }
fi

if [ ! -d $output_folder/blast ]; then
    mkdir $output_folder/blast
fi

if [ ! -f $output_folder/blast/"$(basename $bp_input_fasta)".filtered.fasta ]; then
    filterfasta.py $bp_input_fasta $bp_query_min_len $bp_query_max_len $output_folder/blast/"$(basename $bp_input_fasta)".filtered.fasta
fi

bp_input_fasta=$output_folder/blast/"$(basename $bp_input_fasta)".filtered.fasta

if [ ! -d $output_folder/blast/fasta ]; then
    mkdir $output_folder/blast/fasta
    chunkfasta.py $bp_input_fasta $bp_python_chunknumber $output_folder/blast/fasta || { rm -rf $output_folder/blast/fasta ; echo "Error in chunkfasta.py"; exit 1; }
fi
wait

BLASTDBDIR=$bp_blast_BLASTDB_DIR
BLASTDB=$bp_blast_BLASTDB
NODES=$(cat ${PBS_NODEFILE} | sort | uniq)
 
# copy blast databases to ram disk
for node in ${NODES}
  do
    ssh ${node} "mkdir -p /dev/shm/${USER}/BLAST && cp -r ${BLASTDBDIR}/${BLASTDB}* /dev/shm/${USER}/BLAST && echo 'successfully added DBs on ${node}' || exit 1" &
  done

wait  # wait for parallel copies to finish
   
fasta_count=$( find "${output_folder}/blast/fasta" -name "*.fasta" | wc -l  ) 

cmd="blastp -query {} -outfmt '$bp_blast_outfmt' -out {}.xml -db /dev/shm/${USER}/BLAST/${BLASTDB} -max_target_seqs $bp_blast_max_target_seqs -max_hsps $bp_blast_max_hsps -num_threads '$bp_blast_num_threads' -evalue '$bp_blast_evalue' -matrix '$bp_blast_matrix' -gapopen '$bp_blast_gap_open' -gapextend '$bp_blast_gap_extend' -word_size '$bp_blast_word_size' && blast_XML_to_csv.py {}.xml $bp_input_fasta {}.csv $bp_sum_aln_cutoff  &> {}.log && gzip --best {}"

if [ "${fasta_count}" -ne "0" ]; then
    ls ${output_folder}/blast/fasta/*.fasta | parallel -j $bp_gnu_parallel_j -u --sshloginfile ${PBS_NODEFILE} "cd ${PBS_O_WORKDIR}; ${cmd}"
fi

wait 

fasta_count=$( find "${output_folder}/blast/fasta" -name "*.fasta" | wc -l  ) 
if [ "${fasta_count}" -ne "0" ]; then
    echo 'There are unprocessed fasta files'
    exit 1
fi

# clean up ram disk
for node in ${NODES}
  do
    ssh ${node} "rm -rf /dev/shm/${USER}/BLAST && echo 'successfully deleted DBs on ${node}' || exit 1" &
done
wait

if [ ! -d "${output_folder}/blast/tables" ]; then
    mkdir "${output_folder}/blast/tables"
fi

csv_count=$( find "${output_folder}/blast/fasta" -name "*.csv" | wc -l  ) 
if [ "${csv_count}" -ne "0" ]; then
    mv ${output_folder}/blast/fasta/*.csv ${output_folder}/blast/tables
fi

if [ ! -f "${output_folder}/blast/combined_blast.tsv" ] ; then
    csvcat.py ${output_folder}/blast/tables > ${output_folder}/blast/combined_blast.tsv
fi

# Unipept LCA analysis
if [ "$bp_sum_pept2lca" -eq 1 ] ; then
    if [ ! -d $output_folder/unipept ] ; then
       cmd="cd ${output_folder} && mkdir unipept && csv2unipeptlca.py ${output_folder}/blast/combined_blast.tsv 'hsp.sbjct' ${output_folder}/unipept/"
       echo ${cmd}
       ssh $headnode_user_ip 'cd '$output_folder' && echo "'$cmd'" | qsub -N unipept -P '$unipept_P' -q '$unipept_q' -l '$unipept_l' -l walltime=48:00:00'
    fi
fi



